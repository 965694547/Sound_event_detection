### Reproduce DCASE2019 Task4 challenge results  
We submitted 4 systems (Lin_ICT_task_4_1, Lin_ICT_task_4_2, Lin_ICT_task_4_3, Lin_ICT_task_4_4) to the challenge and Lin_ICT_task3 performs the best on the eval set.    
The top1-top6 (performance on validation set) models in our experiments are as following:  

top1:   GL-0.99   0.444743  challenge_results/model_weights/444743/best_model_w.h5  
top2:   GL-0.996  0.440152  challenge_results/model_weights/440152/best_model_w.h5  
top3:   GL-1      0.440134  challenge_results/model_weights/440134/best_model_w.h5  
top4:   GL-0.99   0.439307  challenge_results/model_weights/439307/best_model_w.h5  
top5:   GL-0.996  0.438022  challenge_results/model_weights/438022/best_model_w.h5  
top6:   GL-0.996  0.437296  challenge_results/model_weights/437296/best_model_w.h5  
  
Lin_ICT_task_4_1: top1 model        0.444743      
Lin_ICT_task_4_2: top2 model        0.440152  
Lin_ICT_task_4_3: the ensemble of top1 to top6 models     0.452848  
Lin_ICT_task_4_4: the ensemble of top2 to top6 models     0.454330  
