### Reproduce DCASE2019 Task4 challenge results  
We submitted 4 systems (Lin_ICT_task_4_1, Lin_ICT_task_4_2, Lin_ICT_task_4_3, Lin_ICT_task_4_4) to the challenge and Lin_ICT_task3 performs the best on the eval set.    

The top1-top6 (performance on validation set) models in our experiments are as following:  

top1:&nbsp;  GL-0.99&nbsp;  0.444743&nbsp;  challenge_results/model_weights/444743/best_model_w.h5  
top2:&nbsp;  GL-0.996&nbsp;  0.440152&nbsp;  challenge_results/model_weights/440152/best_model_w.h5  
top3:&nbsp;  GL-1&nbsp;  0.440134&nbsp;  challenge_results/model_weights/440134/best_model_w.h5  
top4:&nbsp;  GL-0.99&nbsp;  0.439307&nbsp;  challenge_results/model_weights/439307/best_model_w.h5  
top5:&nbsp;  GL-0.996&nbsp;  0.438022&nbsp;  challenge_results/model_weights/438022/best_model_w.h5  
top6:&nbsp;  GL-0.996&nbsp;  0.437296&nbsp;  challenge_results/model_weights/437296/best_model_w.h5  
  
Lin_ICT_task_4_1:&nbsp;  top1 model&nbsp;  0.444743      
Lin_ICT_task_4_2:&nbsp;  top2 model&nbsp;  0.440152  
Lin_ICT_task_4_3:&nbsp;  the ensemble of top1 to top6 models&nbsp;  0.452848  
Lin_ICT_task_4_4:&nbsp;  the ensemble of top2 to top6 models&nbsp;  0.454330  
